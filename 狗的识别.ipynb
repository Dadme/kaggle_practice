{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "狗的识别.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dadme/kaggle_practice/blob/master/%E7%8B%97%E7%9A%84%E8%AF%86%E5%88%AB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9B3a4wYUMBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "import math\n",
        "from mxnet import autograd, gluon, init, nd\n",
        "from mxnet.gluon import data as gdata, loss as gloss, model_zoo, nn\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import zipfile\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmJiwrvXOAnp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSIHBQxYVFDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH-GEBOvVHkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!echo '{\"username\":\"shengleiwhut\",\"key\":\"5282ff6fee554360bfff9a7324afb7e4\"}' > /root/.kaggle/kaggle.json\n",
        "! chmod 600  /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYZZ54OVVNRy",
        "colab_type": "code",
        "outputId": "b7fed271-f06f-4c7b-f265-94d9baf6d6b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "!kaggle competitions download -c dog-breed-identification"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading labels.csv.zip to /content\n",
            "\r  0% 0.00/214k [00:00<?, ?B/s]\n",
            "\r100% 214k/214k [00:00<00:00, 80.8MB/s]\n",
            "sample_submission.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Downloading test.zip to /content\n",
            " 97% 335M/346M [00:01<00:00, 228MB/s]\n",
            "100% 346M/346M [00:01<00:00, 199MB/s]\n",
            "Downloading train.zip to /content\n",
            " 98% 337M/345M [00:01<00:00, 201MB/s]\n",
            "100% 345M/345M [00:01<00:00, 184MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bvtMVuLVn1y",
        "colab_type": "code",
        "outputId": "f0e55bd0-2b1b-483a-be06-1ecc47c8a179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labels.csv.zip\tsample_data\t\t   test.zip   utils.py\n",
            "__pycache__\tsample_submission.csv.zip  train.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1onbYO3PVtnS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir data\n",
        "!mv train.zip data\n",
        "!mv test.zip data\n",
        "!mv labels.csv.zip data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSOX9EXvWJVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import utils "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXuCInjhV28a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = 'data'\n",
        "zipfiles = ['train.zip', 'test.zip', 'labels.csv.zip']\n",
        "for f in zipfiles:\n",
        "    with zipfile.ZipFile(data_dir + '/' + f, 'r') as z:\n",
        "        z.extractall(data_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1K7-KPVWAT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reorg_train_valid(data_dir, train_dir, input_dir, valid_ratio, idx_label):\n",
        "    # 训练集中数量最少一类的狗的样本数\n",
        "    min_n_train_per_label = (\n",
        "        collections.Counter(idx_label.values()).most_common()[:-2:-1][0][1])\n",
        "    # 验证集中每类狗的样本数\n",
        "    n_valid_per_label = math.floor(min_n_train_per_label * valid_ratio)\n",
        "    label_count = {}\n",
        "    for train_file in os.listdir(os.path.join(data_dir, train_dir)):\n",
        "        idx = train_file.split('.')[0]\n",
        "        label = idx_label[idx]\n",
        "        utils.mkdir_if_not_exist([data_dir, input_dir, 'train_valid', label])\n",
        "        shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
        "                    os.path.join(data_dir, input_dir, 'train_valid', label))\n",
        "        if label not in label_count or label_count[label] < n_valid_per_label:\n",
        "            utils.mkdir_if_not_exist([data_dir, input_dir, 'valid', label])\n",
        "            shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
        "                        os.path.join(data_dir, input_dir, 'valid', label))\n",
        "            label_count[label] = label_count.get(label, 0) + 1\n",
        "        else:\n",
        "            utils.mkdir_if_not_exist([data_dir, input_dir, 'train', label])\n",
        "            shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
        "                        os.path.join(data_dir, input_dir, 'train', label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMd9zEOyWMqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reorg_dog_data(data_dir, label_file, train_dir, test_dir, input_dir,\n",
        "                   valid_ratio):\n",
        "    # 读取训练数据标签\n",
        "    with open(os.path.join(data_dir, label_file), 'r') as f:\n",
        "        lines = f.readlines()[1:]\n",
        "        tokens = [l.rstrip().split(',') for l in lines]\n",
        "        idx_label = dict(((idx, label) for idx, label in tokens))\n",
        "    reorg_train_valid(data_dir, train_dir, input_dir, valid_ratio, idx_label)\n",
        "\n",
        "    utils.mkdir_if_not_exist([data_dir, input_dir, 'test', 'unknown'])\n",
        "    for test_file in os.listdir(os.path.join(data_dir, test_dir)):\n",
        "        shutil.copy(os.path.join(data_dir, test_dir, test_file),\n",
        "                    os.path.join(data_dir, input_dir, 'test', 'unknown'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vPgDAllWQza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_file, train_dir, test_dir = 'labels.csv', 'train', 'test'\n",
        "input_dir, batch_size, valid_ratio = 'train_valid_test', 128, 0.1\n",
        "reorg_dog_data(data_dir, label_file, train_dir, test_dir, input_dir,\n",
        "                   valid_ratio)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvvQlZYiWU0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform_train = gdata.vision.transforms.Compose([\n",
        "    gdata.vision.transforms.RandomResizedCrop(224, scale=(0.08, 1.0),\n",
        "                                              ratio=(3.0/4.0, 4.0/3.0)),\n",
        "    gdata.vision.transforms.RandomFlipLeftRight(),\n",
        "    gdata.vision.transforms.RandomColorJitter(brightness=0.4, contrast=0.4,\n",
        "                                              saturation=0.4),\n",
        "    gdata.vision.transforms.RandomLighting(0.1),\n",
        "    gdata.vision.transforms.ToTensor(),\n",
        "    gdata.vision.transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                      [0.229, 0.224, 0.225])])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFTalrjCWZ1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform_test = gdata.vision.transforms.Compose([\n",
        "    gdata.vision.transforms.Resize(256),\n",
        "    gdata.vision.transforms.CenterCrop(224),\n",
        "    gdata.vision.transforms.ToTensor(),\n",
        "    gdata.vision.transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                      [0.229, 0.224, 0.225])])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6-NB5mJWdVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = gdata.vision.ImageFolderDataset(\n",
        "    os.path.join(data_dir, input_dir, 'train'), flag=1)\n",
        "valid_ds = gdata.vision.ImageFolderDataset(\n",
        "    os.path.join(data_dir, input_dir, 'valid'), flag=1)\n",
        "train_valid_ds = gdata.vision.ImageFolderDataset(\n",
        "    os.path.join(data_dir, input_dir, 'train_valid'), flag=1)\n",
        "test_ds = gdata.vision.ImageFolderDataset(\n",
        "    os.path.join(data_dir, input_dir, 'test'), flag=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItoNV4QjWgWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iter = gdata.DataLoader(train_ds.transform_first(transform_train),\n",
        "                              batch_size, shuffle=True, last_batch='keep')\n",
        "valid_iter = gdata.DataLoader(valid_ds.transform_first(transform_test),\n",
        "                              batch_size, shuffle=True, last_batch='keep')\n",
        "train_valid_iter = gdata.DataLoader(train_valid_ds.transform_first(\n",
        "    transform_train), batch_size, shuffle=True, last_batch='keep')\n",
        "test_iter = gdata.DataLoader(test_ds.transform_first(transform_test),\n",
        "                             batch_size, shuffle=False, last_batch='keep')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tN00kmNAWjUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_net(ctx):\n",
        "    finetune_net = model_zoo.vision.resnet34_v2(pretrained=True)\n",
        "    # 定义输出网络\n",
        "    finetune_net.output_new = nn.HybridSequential(prefix='')\n",
        "    finetune_net.output_new.add(nn.Dense(256, activation='relu'))\n",
        "    # 输出的类别120\n",
        "    finetune_net.output_new.add(nn.Dense(120))\n",
        "    # 初始化输出网络\n",
        "    finetune_net.output_new.initialize(init.Xavier(), ctx=ctx)\n",
        "    finetune_net.collect_params().reset_ctx(ctx)\n",
        "    return finetune_net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u8e4I6AWmbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = gloss.SoftmaxCrossEntropyLoss()\n",
        "\n",
        "def evaluate_loss(data_iter, net, ctx):\n",
        "    l_sum, n = 0.0, 0\n",
        "    for X, y in data_iter:\n",
        "        y = y.as_in_context(ctx)\n",
        "        output_features = net.features(X.as_in_context(ctx))\n",
        "        outputs = net.output_new(output_features)\n",
        "        l_sum += loss(outputs, y).sum().asscalar()\n",
        "        n += y.size\n",
        "    return l_sum / n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_ib-c4vWpfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(net, train_iter, valid_iter, num_epochs, lr, wd, ctx, lr_period,\n",
        "          lr_decay):\n",
        "    trainer = gluon.Trainer(net.output_new.collect_params(), 'sgd',\n",
        "                            {'learning_rate': lr, 'momentum': 0.9, 'wd': wd})\n",
        "    for epoch in range(num_epochs):\n",
        "        train_l_sum, n, start = 0.0, 0, time.time()\n",
        "        if epoch > 0 and epoch % lr_period == 0:\n",
        "            trainer.set_learning_rate(trainer.learning_rate * lr_decay)\n",
        "        for X, y in train_iter:\n",
        "            y = y.as_in_context(ctx)\n",
        "            output_features = net.features(X.as_in_context(ctx))\n",
        "            with autograd.record():\n",
        "                outputs = net.output_new(output_features)\n",
        "                l = loss(outputs, y).sum()\n",
        "            l.backward()\n",
        "            trainer.step(batch_size)\n",
        "            train_l_sum += l.asscalar()\n",
        "            n += y.size\n",
        "        time_s = \"time %.2f sec\" % (time.time() - start)\n",
        "        if valid_iter is not None:\n",
        "            valid_loss = evaluate_loss(valid_iter, net, ctx)\n",
        "            epoch_s = (\"epoch %d, train loss %f, valid loss %f, \"\n",
        "                       % (epoch + 1, train_l_sum / n, valid_loss))\n",
        "        else:\n",
        "            epoch_s = (\"epoch %d, train loss %f, \"\n",
        "                       % (epoch + 1, train_l_sum / n))\n",
        "        print(epoch_s + time_s + ', lr ' + str(trainer.learning_rate))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kE47ydFlWttr",
        "colab_type": "code",
        "outputId": "c339e1a1-9978-45b6-e14e-b08576fc8751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "ctx, num_epochs, lr, wd = utils.try_gpu(), 10, 0.01, 1e-4\n",
        "lr_period, lr_decay, net = 10, 0.1, get_net(ctx)\n",
        "net.hybridize()\n",
        "train(net, train_iter, valid_iter, num_epochs, lr, wd, ctx, lr_period,\n",
        "      lr_decay)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Mismatch in the content of model file detected. Downloading again.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading /root/.mxnet/models/resnet34_v2-9d6b80bb.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/resnet34_v2-9d6b80bb.zip...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/mxnet/gluon/utils.py:331: UserWarning: File /root/.mxnet/models/resnet34_v2-9d6b80bb.zip exists in file system so the downloaded file is deleted\n",
            "  'File {} exists in file system so the downloaded file is deleted'.format(fname))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1, train loss 3.300978, valid loss 1.258725, time 77.28 sec, lr 0.01\n",
            "epoch 2, train loss 1.280531, valid loss 0.690924, time 73.18 sec, lr 0.01\n",
            "epoch 3, train loss 1.037039, valid loss 0.566777, time 74.64 sec, lr 0.01\n",
            "epoch 4, train loss 0.962450, valid loss 0.538432, time 75.19 sec, lr 0.01\n",
            "epoch 5, train loss 0.874185, valid loss 0.498418, time 75.21 sec, lr 0.01\n",
            "epoch 6, train loss 0.841072, valid loss 0.485435, time 73.78 sec, lr 0.01\n",
            "epoch 7, train loss 0.831565, valid loss 0.478701, time 73.68 sec, lr 0.01\n",
            "epoch 8, train loss 0.811826, valid loss 0.445610, time 73.71 sec, lr 0.01\n",
            "epoch 9, train loss 0.798864, valid loss 0.456888, time 74.64 sec, lr 0.01\n",
            "epoch 10, train loss 0.764241, valid loss 0.440096, time 72.68 sec, lr 0.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RecB_NdWw6r",
        "colab_type": "code",
        "outputId": "dc603b90-f025-4bae-dd1e-96a4f9337dd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "net = get_net(ctx)\n",
        "net.hybridize()\n",
        "train(net, train_valid_iter, None, num_epochs, lr, wd, ctx, lr_period,\n",
        "      lr_decay)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1, train loss 3.185491, time 81.29 sec, lr 0.01\n",
            "epoch 2, train loss 1.238360, time 80.17 sec, lr 0.01\n",
            "epoch 3, train loss 0.995190, time 78.75 sec, lr 0.01\n",
            "epoch 4, train loss 0.928841, time 78.61 sec, lr 0.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7az-pxxaY8t",
        "colab_type": "code",
        "outputId": "1a47c56e-6c29-4fe7-b72b-f58edeff3a3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 130811 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.3-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.3-0ubuntu3~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.3-0ubuntu3~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUc6D9bRds-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU5OaH3deQis",
        "colab_type": "code",
        "outputId": "2f44d610-431b-4f2d-ff64-a09d0ca858e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Colab Notebooks'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0JsOeboeUKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = []\n",
        "for data, label in test_iter:\n",
        "    output_features = net.features(data.as_in_context(ctx))\n",
        "    output = nd.softmax(net.output_new(output_features))\n",
        "    preds.extend(output.asnumpy())\n",
        "ids = sorted(os.listdir(os.path.join(data_dir, input_dir, 'test/unknown')))\n",
        "with open('drive/submission.csv', 'w') as f:\n",
        "    f.write('id,' + ','.join(train_valid_ds.synsets) + '\\n')\n",
        "    for i, output in zip(ids, preds):\n",
        "        f.write(i.split('.')[0] + ',' + ','.join(\n",
        "            [str(num) for num in output]) + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqDLTBjJefqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}